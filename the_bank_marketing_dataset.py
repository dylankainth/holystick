# -*- coding: utf-8 -*-
"""The Bank Marketing Dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EO1f99dWDnOlBGZNNo3yZv9WEwDzVcLY
"""

file_path = 'bank-full.csv'

from holisticai.datasets import load_dataset

import pandas as pd
df = pd.read_csv(file_path, sep=';')
df.head()

# Check the shape (number of rows and columns) of the dataset
print("Dataset Shape:", df.shape)

# Check the total number of rows and columns separately
print("Number of Rows:", df.shape[0])  # Number of rows
print("Number of Columns:", df.shape[1])  # Number of columns

print(df.info())

print(df.isnull().sum())

"""EDA"""

print(df.describe())
df['age'].hist()

print(df['job'].value_counts())

y_unique_values = df['y'].unique()
print("Unique values in 'y':", y_unique_values)

df['y'] = df['y'].map({'yes': 1, 'no': 0})
df.head()

"""data visualisation to understand the marital status, education, housing, loan, campaign  againt y (target)


"""

import seaborn as sns
import matplotlib.pyplot as plt

# Set a style for better visualizations
sns.set(style="whitegrid")

plt.figure(figsize=(10, 6))
sns.countplot(x='marital', hue='y', data=df)
plt.title('Marital Status vs Subscription')
plt.xlabel('Marital Status')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.legend(title='Subscribed')
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(x='education', hue='y', data=df)
plt.title('Education Level vs Subscription')
plt.xlabel('Education Level')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.legend(title='Subscribed')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
sns.countplot(x='housing', hue='y', data=df)
plt.title('Housing vs Subscription')
plt.xlabel('Housing')
plt.ylabel('Count')
plt.legend(title='Subscribed')
plt.show()

plt.figure(figsize=(8, 5))
sns.countplot(x='loan', hue='y', data=df)
plt.title('Loan vs Subscription')
plt.xlabel('Loan')
plt.ylabel('Count')
plt.legend(title='Subscribed')
plt.show()

"""- Marital Status: Are married individuals more likely to subscribe compared to single or divorced clients?
- Education Level: Does having a higher education increase the chances of subscribing?
- Housing and Loan Status: Do clients with housing or personal loans tend to decline or accept offers more?
- Campaign Effectiveness: Does persistence in contacting the clients affect the subscription outcome?
"""

df.head()

"""Encoding before model building

- job
- marital
- education
- default
- housing
- loan
- contact?
- poutcome?
- y (encoded)
"""

# List of columns to check for unique values
columns_to_check = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome' , 'month']

# Check unique values for each column in the list
for column in columns_to_check:
    unique_values = df[column].unique()
    print(f"Unique values in column '{column}': {unique_values}")
    print("-" * 50)  # Separator for readability

# Columns that need to be one-hot encoded based on the unique values
columns_to_encode = ['job', 'marital', 'education', 'contact', 'poutcome', 'month']

# One-Hot Encode the categorical columns
df_encoded = pd.get_dummies(df, columns=columns_to_encode, drop_first=True)

# Encode binary columns with 'yes'/'no' using mapping for simplicity
binary_columns = ['default', 'housing', 'loan']
for column in binary_columns:
    df_encoded[column] = df_encoded[column].map({'yes': 1, 'no': 0})

df_encoded.head()

# Convert all boolean columns to integer values (0 and 1)
df_encoded = df_encoded.astype(int)
df_encoded.head()

df_encoded.columns

"""Scaling numerical features"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
numeric_columns = ['age', 'balance', 'duration', 'day']
df_encoded[numeric_columns] = scaler.fit_transform(df_encoded[numeric_columns])

# Display the first few rows to see the scaled values
print("First few rows of scaled features:")
df_encoded[numeric_columns].head()

df_encoded.head()

corr_matrix = df_encoded.corr()

plt.figure(figsize=(16, 12))

sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', linewidths=0.5, linecolor='white')

plt.title("Correlation Heatmap for Encoded Features", fontsize=18)

plt.show()

"""1. Most Features Have Weak Correlations:

You can see that the majority of the cells in the heatmap are either light blue or light red, indicating that many features have weak correlations with each other.
This is common for datasets with encoded categorical features because most encoded categories are inherently independent.
2. Strong Positive Correlations:

You may notice a few pairs with dark red shades indicating strong positive correlations.
For example, some job categories or marital status may have high correlations if they tend to co-occur (e.g., certain jobs are more likely for married people).
This could imply redundancy in the feature set, where similar information is being represented multiple times.
3. Negative Correlations:

There are some dark blue areas in the heatmap, which indicate negative correlations between certain features.
For example, some categorical features that are mutually exclusive, like different types of jobs or educational levels, are negatively correlated.
Such negative correlations can sometimes help the model learn boundaries between different classes.
4. Correlation with Target Variable (y):

One column to pay attention to is the y column, which is your target variable indicating whether the client subscribed to the term deposit.
Features with a strong positive or negative correlation with y could be more influential for predicting whether a client subscribes.
In this heatmap, look at the y row and column to identify any red or blue shades that are more intense. These features are potentially more useful for your model.
"""

# Extract the correlation values of all features with the target variable 'y'
corr_with_target = df_encoded.corr()[['y']].drop('y')

# Plot the heatmap for correlations with the target variable
plt.figure(figsize=(8, 10))
sns.heatmap(corr_with_target, annot=True, cmap='coolwarm', linewidths=0.5, linecolor='white', vmin=-1, vmax=1)
plt.title('Heatmap of Feature Correlations with Target Variable (y)', fontsize=16)
plt.xlabel('Target Variable (y)')
plt.ylabel('Features')
plt.show()

"""**Features with Low Correlation (Consider Removing):**
Features with correlation close to zero likely do not have a strong relationship with the target and could potentially be removed:
job_blue-collar (-0.072), job_entrepreneur (-0.02), job_services (-0.028), contact_unknown (-0.15), job_unemployed (0.02), education_secondary (-0.036), month_mar (0.13), etc.
Features such as contact_unknown (-0.15) and housing (-0.14) have negative correlations but are still relatively low. These may add noise rather than provide useful information.
job_unknown (0.00027), job_self-employed (0.00086), etc. have almost no correlation with y. These should definitely be removed as they likely contribute nothing useful to the model.
**Negative Correlations to Consider:**
poutcome_unknown (-0.17) and housing (-0.14):
These features have notable negative correlations with the target variable. A negative correlation means that these features are inversely related to the probability of subscribing (y).
Depending on the model you choose, features like this may still be valuable to include if their impact is consistent and significant.

split training and test set
"""

from sklearn.model_selection import train_test_split

# Separate the features and the target variable
X = df_encoded.drop('y', axis=1)  # Features: dropping the target column 'y'
y = df_encoded['y']                # Target: selecting the target column 'y'

# Split the data into training and testing sets
# Usually, a 70-30 or 80-20 split is common
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Display the shapes of the resulting splits to confirm everything looks good
print(f"Training features shape: {X_train.shape}")
print(f"Training labels shape: {y_train.shape}")
print(f"Testing features shape: {X_test.shape}")
print(f"Testing labels shape: {y_test.shape}")

"""Random Forest"""

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(X_train, y_train)
print(rf.score(X_test, y_test))

"""Model evaluation -
Use metrics such as accuracy, precision, recall, F1-score, and AUC-ROC
"""

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, roc_curve, auc

# Make predictions on the test set
y_pred = rf.predict(X_test)
y_pred_proba = rf.predict_proba(X_test)[:, 1]  # Probability estimates to use for ROC-AUC

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

# Precision
precision = precision_score(y_test, y_pred)
print(f"Precision: {precision:.2f}")

# Recall
recall = recall_score(y_test, y_pred)
print(f"Recall: {recall:.2f}")

# F1 Score
f1 = f1_score(y_test, y_pred)
print(f"F1 Score: {f1:.2f}")

# AUC-ROC
auc_roc = roc_auc_score(y_test, y_pred_proba)
print(f"AUC-ROC: {auc_roc:.2f}")

# Optionally, display the full classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Plotting the ROC Curve for a visual perspective
import matplotlib.pyplot as plt

fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

plt.figure()
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

"""True Positive Rate (TPR), on the Y-axis, measures the ability of your model to correctly identify positive samples (clients who subscribed, for instance).
False Positive Rate (FPR), on the X-axis, measures the likelihood that the model incorrectly labels a negative sample as positive (clients who didn't subscribe but were predicted as subscribed).
The curve in your graph (blue line) is well above the diagonal line (random classifier), and it follows closely along the top-left region, meaning:
Your model has a good balance between correctly classifying positive examples while minimizing false positives.
The AUC of 0.93 tells us that your model has a high accuracy in distinguishing between the positive and negative classes across all thresholds.
"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Step 1: Make predictions on the test set
y_pred = rf.predict(X_test)

# Step 2: Generate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Step 3: Visualize the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No', 'Yes'])
disp.plot(cmap='Blues')  # Use cmap to add color to the plot for better visualization
plt.title("Confusion Matrix - Random Forest Classifier")
plt.show()

"""- Random Forest model has performed well in identifying non-subscribers.
- However, there is a significant number of False Negatives (948), meaning many actual subscribers were missed by the model.
- The confusion matrix shows where the model could be tweaked to improve performance—likely reducing False Negatives to ensure more actual subscribers are correctly identified, which is crucial for a marketing campaign aimed at potential customers.

**Holistic AI**

Optimise for trustworthiness (fairness, explainability and robustness)

Bias measuring and mitigation
"""


# make function that allows to estimate y/n based on input into the model
def predict_subscription(input_data):
    # Convert the input data into a DataFrame
    input_df = pd.DataFrame([input_data])

    # One-hot encode the categorical columns
    input_df_encoded = pd.get_dummies(input_df, columns=columns_to_encode, drop_first=True)

    # Ensure the input data has all the columns from the training set
    input_df_encoded = input_df_encoded.reindex(columns=df_encoded.columns, fill_value=0)

    # Scale the numerical features
    input_df_encoded[numeric_columns] = scaler.transform(input_df_encoded[numeric_columns])

    # Make predictions using the trained model
    prediction = rf.predict(input_df_encoded)

    # Return the prediction
    return prediction[0]

# test the function
input_data = {
    'age': 35,
    'job': 'admin.',
    'marital': 'single',
    'education': 'secondary',
    'default': 'no',
    'balance': 1000,
    'housing': 'yes',
    'loan': 'no',
    'contact': 'cellular',
    'day': 15,
    'month': 'may',
    'duration': 200,
    'pdays': -1,
    'previous': 0,
    'poutcome': 'unknown'
}

prediction = predict_subscription(input_data)
print(prediction)